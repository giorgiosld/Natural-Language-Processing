{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giorgiosld/Natural-Language-Processing/blob/main/lab4/T_725_Lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pajD7caf9pX7"
      },
      "source": [
        "# T-725 Natural Language Processing: Lab 4\n",
        "In today's lab, we will be working with part-of-speech tagging, parsing, and chunking.\n",
        "\n",
        "To begin with, do the following:\n",
        "* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n",
        "* Select `\"Runtime\" > \"Run all\"` to run the code in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeVrNw6DTouq"
      },
      "source": [
        "## Setting up\n",
        "Let's start off by installing the `svgling` library for drawing syntax trees, as well as defining a function to evaluate the grammars that we will be creating in today's lab assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX7HBL8VA73R"
      },
      "source": [
        "!pip install svgling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cU_cWGK3LJl"
      },
      "source": [
        "# Compare trees generated by a parser to correct trees\n",
        "\n",
        "def evaluate_parser(parser, sentences, correct):\n",
        "  correct_trees = [nltk.Tree.fromstring(t) for t in correct]\n",
        "  num_sentences = len(sentences)\n",
        "\n",
        "  for num, (sent, correct_tree) in enumerate(zip(sentences, correct_trees)):\n",
        "    print(f\">{sent}\\n\")\n",
        "\n",
        "    error = None\n",
        "    print_tree = False\n",
        "\n",
        "    try:\n",
        "      my_trees = list(parser.parse(sent.split()))\n",
        "    except ValueError as e:\n",
        "      print(e)\n",
        "      my_trees = []\n",
        "\n",
        "    if len(my_trees) > 1:\n",
        "      error = f\"Generated {len(my_trees)} trees (should only generate one)!\"\n",
        "    elif len(my_trees) == 0:\n",
        "      error = \"Couldn't parse sentence.\"\n",
        "    else:\n",
        "      my_tree = my_trees[0]\n",
        "      if my_tree != correct_tree:\n",
        "        error = \"Generated an incorrect tree\"\n",
        "        print_tree = True\n",
        "\n",
        "    if error:\n",
        "      print(error)\n",
        "\n",
        "      if print_tree:\n",
        "        print(\"\\nYour tree:\")\n",
        "        my_tree.pretty_print()\n",
        "\n",
        "      print(\"\\nCorrect tree:\")\n",
        "      correct_tree.pretty_print()\n",
        "    else:\n",
        "      print(\"Correct!\\n\")\n",
        "\n",
        "    if num != num_sentences - 1:\n",
        "      print(\"============================\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPZAz_G-guVT"
      },
      "source": [
        "## Context free grammars (CFG) in NLTK\n",
        "\n",
        "[Example 3.1](https://www.nltk.org/book/ch08.html#sec-context-free-grammar) in chapter 8 of the NLTK book shows how we define a context free grammar (CFG) and use it to parse sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpN8fLI5gyIs"
      },
      "source": [
        "import nltk\n",
        "\n",
        "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\" | \"ate\" | \"walked\"\n",
        "  NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
        "  Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
        "  N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
        "  P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
        "  \"\"\")\n",
        "\n",
        "sent = \"Mary saw Bob\".split()\n",
        "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
        "for tree in rd_parser.parse(sent):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-QjUlbt67JO"
      },
      "source": [
        "## Visualizing parse trees with NLTK\n",
        "We can use NLTK to draw a graphical diagram of a syntax tree. Unfortunately, this functionality does not work on Google Colab. We can still print it as text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QsWHp88BpnV"
      },
      "source": [
        "from nltk import Tree\n",
        "t = Tree.fromstring('(S (NP this tree) (VP (V is) (ADJ pretty)))')\n",
        "\n",
        "# NLTK won't draw the tree if we're using Google Colab\n",
        "# t.draw()\n",
        "\n",
        "# But we can still print a text diagram\n",
        "t.pretty_print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk35SqLwBt07"
      },
      "source": [
        "We can also use a different library, `svgling`, to draw trees:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5miut6O2RX4"
      },
      "source": [
        "import svgling\n",
        "\n",
        "svgling.draw_tree(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW87mEBNc1bm"
      },
      "source": [
        "## Probabilistic context free grammar (PCFG) in NLTK\n",
        "[Example 6.4](https://www.nltk.org/book/ch08.html#code-pcfg1) in chapter 8 of the NLTK book shows how to define a probabilistic context free grammar (PCFG) and use it to produce the most likely tree for a given sentence. Note that the productions for each category must add up to 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUl9Y84Xc4q7"
      },
      "source": [
        "import nltk\n",
        "\n",
        "grammar = nltk.PCFG.fromstring(\"\"\"\n",
        "    S    -> NP VP              [1.0]\n",
        "    VP   -> TV NP              [0.4]\n",
        "    VP   -> IV                 [0.3]\n",
        "    VP   -> DatV NP NP         [0.3]\n",
        "    TV   -> 'saw'              [1.0]\n",
        "    IV   -> 'ate'              [1.0]\n",
        "    DatV -> 'gave'             [1.0]\n",
        "    NP   -> 'telescopes'       [0.8]\n",
        "    NP   -> 'Jack'             [0.2]\n",
        "    \"\"\")\n",
        "\n",
        "viterbi_parser = nltk.ViterbiParser(grammar)\n",
        "\n",
        "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i6sbasGdAKp"
      },
      "source": [
        "This is equivalent to:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ctRtCGodBZO"
      },
      "source": [
        "grammar = nltk.PCFG.fromstring(\"\"\"\n",
        "    S    -> NP VP [1.0]\n",
        "    VP   -> TV NP [0.4] | IV [0.3] | DatV NP NP [0.3]\n",
        "    TV   -> 'saw' [1.0]\n",
        "    IV   -> 'ate' [1.0]\n",
        "    DatV -> 'gave' [1.0]\n",
        "    NP   -> 'telescopes' [0.8] | 'Jack' [0.2]\n",
        "    \"\"\")\n",
        "\n",
        "viterbi_parser = nltk.ViterbiParser(grammar)\n",
        "\n",
        "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
        "  print(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ_LwBbqCpFC"
      },
      "source": [
        "## Chunking with NLTK\n",
        "NLTK's taggers can be used for more than just assigning part-of-speech tags to tokens. They can also be trained to assign chunk tags to chunks. [Example 3.1](https://www.nltk.org/book/ch07.html#code-unigram-chunker) in chapter 7 of the NLTK book shows how to build a chunker with a unigram tagger:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDHiJRSVgyAa"
      },
      "source": [
        "class UnigramChunker(nltk.ChunkParserI):\n",
        "    def __init__(self, train_sents):\n",
        "        train_data = [[(t, c) for w, t, c in nltk.chunk.tree2conlltags(sent)]\n",
        "                      for sent in train_sents]\n",
        "\n",
        "        self.tagger = nltk.UnigramTagger(train_data)\n",
        "\n",
        "    def parse(self, sentence):\n",
        "        pos_tags = [pos for (word,pos) in sentence]\n",
        "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
        "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
        "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
        "                     in zip(sentence, chunktags)]\n",
        "        return nltk.chunk.conlltags2tree(conlltags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZmBRsyEK_mX"
      },
      "source": [
        "We can train it and evaluate it on the CoNLL 2000 corpus, which contains chunk IOB tags (I-inside, O-outside, B-begin) as well as POS tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKkqpHy7cGFP"
      },
      "source": [
        "from nltk.corpus import conll2000\n",
        "nltk.download('conll2000')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
        "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
        "\n",
        "chunker = UnigramChunker(train_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyuwvS4SEY2l"
      },
      "source": [
        "Now that we've trained an NP chunker, we can try chunking a sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEOUG6OjchU4"
      },
      "source": [
        "import svgling\n",
        "sentence = nltk.pos_tag('The little yellow dog barked at the cat.'.split())\n",
        "\n",
        "tree = chunker.parse(sentence)\n",
        "print(tree)\n",
        "\n",
        "# Note that we can't pretty_print() partial trees, but we can still draw them\n",
        "# using svgling\n",
        "svgling.draw_tree(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftx95svvFbl8"
      },
      "source": [
        "We can also see how well the chunker performs by evaluating it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLhQqTAvcY4w"
      },
      "source": [
        "print(chunker.evaluate(test_sents))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPSLZUxt9uMY"
      },
      "source": [
        "# Assignment\n",
        "Answer the following questions and hand in your solution in Canvas before 8:30 Monday morning, September 25th. Remember to save your file before uploading it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoHGDZBi9_Dr"
      },
      "source": [
        "## Question 1\n",
        "Part-of-Speech Tagging\n",
        "\n",
        "Complete the following tasks:\n",
        "1. Use `gutenberg.sents(filename)` to get the tokenized sentences of *The Innocence of Father Brown* by G. K. Chesterton (`chesterton-brown.txt`).\n",
        "2. Tag the sentences using `nltk.pos_tag_sents(tokenized_sentences)`.\n",
        "3. Use a list comprehension to create a single list with all the tags.\n",
        "4. Use `nltk.FreqDist()` to count the tags, and generate a frequency list (with all the tags) using `.most_common()`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsdCBJOhV9_q"
      },
      "source": [
        "from nltk.corpus import gutenberg\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Required for nltk.pos_tag_sents()\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fpsMZWc9_lF"
      },
      "source": [
        "# Your solution here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOkrqZMxgACA"
      },
      "source": [
        "## Question 2\n",
        "Add to `q1_grammar` below until the sentence can be correctly parsed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij_iKAtZef18"
      },
      "source": [
        "q1_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S  -> NP VP\n",
        "  \"\"\")\n",
        "\n",
        "q1_parser = nltk.ChartParser(q1_grammar)\n",
        "\n",
        "# Evaluate the parser\n",
        "q1_sents = [\"sunsets on mars are blue\"]\n",
        "q1_correct = [\"(S (NP (NP (N sunsets)) (PP (P on) (NP (N mars)))) (VP (V are) (ADJ blue)))\"]\n",
        "\n",
        "evaluate_parser(q1_parser, q1_sents, q1_correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NMelDhZgAsH"
      },
      "source": [
        "## Question 3\n",
        "Make the following changes to `q2_grammar` below:\n",
        "1. Replace the noun category (N) with singular nouns (NN) and plural nouns (NNS).\n",
        "2. Add a category for cardinal numbers (CD).\n",
        "3. Add a category for adverbs (ADV).\n",
        "4. Add a category for personal pronouns (PRP).\n",
        "\n",
        "Adjust your grammar so that the sentences below are parsed correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdeFmt5fiNd"
      },
      "source": [
        "q2_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S  -> NP VP\n",
        "  NP -> NP PP | N | DT ADJ N\n",
        "  VP -> V NP\n",
        "  PP -> P NP\n",
        "  DT -> 'the'\n",
        "  N -> 'venus' | 'planet' | 'earth'\n",
        "  ADJ -> 'closest'\n",
        "  V -> 'is'\n",
        "  P -> 'to'\n",
        "  \"\"\")\n",
        "\n",
        "q2_parser = nltk.ChartParser(q2_grammar)\n",
        "\n",
        "# Facts\n",
        "q2_facts = [\n",
        "    \"venus is the closest planet to earth\",\n",
        "    \"the sun is halfway through its life\",\n",
        "    \"saturn has 82 known moons\"\n",
        "]\n",
        "\n",
        "# Evaluate the parser\n",
        "q2_correct = [\n",
        "    \"(S (NP (NN venus)) (VP (V is) (NP (NP (DT the) (ADJ closest) (NN planet)) (PP (P to) (NP (NN earth))))))\",\n",
        "    \"(S (NP (DT the) (NN sun)) (VP (V is) (PP (ADV halfway) (P through) (NP (PRP its) (NN life)))))\",\n",
        "    \"(S (NP (NN saturn)) (VP (V has) (NP (CD 82) (ADJ known) (NNS moons))))\"\n",
        "]\n",
        "\n",
        "evaluate_parser(q2_parser, q2_facts, q2_correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w9_wU0FgBXl"
      },
      "source": [
        "## Question 4\n",
        "Replace the verb category (V) with transitive (TV) and intransitive (IV) verbs and adjust the grammar so that the sentences below are correctly parsed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvpK5j_0gBsA"
      },
      "source": [
        "q3_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S  -> NP VP\n",
        "  NP -> DT N N | N | CD\n",
        "  VP -> V PP PP | V NP PP\n",
        "  PP -> P | P NP\n",
        "  DT -> 'the'\n",
        "  N -> 'curiosity' | 'rover' | 'mars' | 'nasa' | 'perseverence'\n",
        "  V -> 'arrived' | 'launched'\n",
        "  P -> 'on' | 'in'\n",
        "  CD -> '2012' | '2020'\n",
        "  \"\"\")\n",
        "\n",
        "q3_parser = nltk.ChartParser(q3_grammar)\n",
        "\n",
        "# Facts\n",
        "q3_facts = [\n",
        "    \"the curiosity rover arrived on mars in 2012\",\n",
        "    \"nasa launched the perseverence rover in 2020\"\n",
        "]\n",
        "\n",
        "# Evaluate the parser\n",
        "q3_correct = [\n",
        "    \"(S (NP (DT the) (N curiosity) (N rover)) (VP (IV arrived) (PP (P on) (NP (N mars))) (PP (P in) (NP (CD 2012)))))\",\n",
        "    \"(S (NP (N nasa)) (VP (TV launched) (NP (DT the) (N perseverence) (N rover)) (PP (P in) (NP (CD 2020)))))\"\n",
        "]\n",
        "\n",
        "evaluate_parser(q3_parser, q3_facts, q3_correct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuXRMrwlgxNP"
      },
      "source": [
        "## Question 5\n",
        "The following grammar produces two trees for the sentence *John saw a man with binoculars*. Each tree represents a different interpretation of the sentence. One tree implies that John used binoculars to see a man, while the other implies that a man with binoculars was seen by John.\n",
        "\n",
        "Change the grammar into a **probabilistic CFG** and replace the `ChartParser` with a `ViterbiParser`, which only outputs the most probable tree. Adjust the probabilities so that the parser produces the tree that implies that John saw a man who had binoculars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOW8FEqCghlf"
      },
      "source": [
        "q1_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "  S -> NP VP\n",
        "  NP -> N | NP PP | DT N\n",
        "  VP -> V NP | V NP PP\n",
        "  PP -> P NP\n",
        "  V -> \"saw\"\n",
        "  DT -> \"a\"\n",
        "  N -> \"John\" | \"man\" | \"binoculars\"\n",
        "  P -> \"with\"\n",
        "  \"\"\")\n",
        "\n",
        "sentence = \"John saw a man with binoculars\".split()\n",
        "\n",
        "q1_parser = nltk.ChartParser(q1_grammar)\n",
        "trees = q1_parser.parse(sentence)\n",
        "\n",
        "for tree in trees:\n",
        "  print(tree)\n",
        "  tree.pretty_print()\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqEJsm0Lgxq7"
      },
      "source": [
        "## Question 6\n",
        "Create a new class, `TrigramChunker`, based on the `UnigramChunker` class defined earlier in the notebook. Modify it so that `self.tagger` is a trigram tagger with a unigram tagger as a backoff (see [5.4 Combining taggers](http://www.nltk.org/book/ch05.html#combining-taggers) in the NLTK book). Train and evaluate your chunker on the CoNLL 2000 corpus (using `train_sents` and `test_sents`, created earlier) and report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUU5D3MiTyF7"
      },
      "source": [
        "# Your solution here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaB4WfIxgyP_"
      },
      "source": [
        "## Question 7\n",
        "Complete the following tasks:\n",
        "\n",
        "1. Create a list of all tagged sentences from `test.txt` in the `conll2000` corpus using its `tagged_sents(filename)` method.\n",
        "\n",
        "2. This should return a list of 2012 tagged sentences. You can access a sentence from the list by its index, e.g., `tagged_sents_list[0]` will return the first tagged sentence. Parse any three of the taggged sentences with your chunker and draw the trees using `svgling.draw_tree(tree)`. Note that the tree will only be drawn if the `draw_tree` method is called at the end of the code block.\n",
        "\n",
        "3. Compare the trees generated by your chunker to the correct trees in `test_sents` (which contains the same sentences in the same order as those returned by the `tagged_sents` method). Does your chunker make any mistakes? If so, give an example of at least one of those mistakes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud4m9fbIomVB"
      },
      "source": [
        "# Your solution here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRSOoRybDD2Y"
      },
      "source": [
        "# Sentence 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U-8hazlkgDW"
      },
      "source": [
        "# Sentence 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJi9QnolC2Q"
      },
      "source": [
        "# Sentence 3\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}