{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giorgiosld/Natural-Language-Processing/blob/main/labs/lab8/T_725_Lab08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otXzaijYhN9A"
      },
      "source": [
        "# T-725 Natural Language Processing: Lab 8\n",
        "In today's lab, we will be working with named entity recognition and information extraction.\n",
        "\n",
        "To begin with, do the following:\n",
        "* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n",
        "* Select `\"Runtime\" > \"Run all\"` to run the code in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "detFWJ_K3a2s"
      },
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-iYPlKHMZtT"
      },
      "source": [
        "## Named entity recognition\n",
        "NLTK includes a classifier for tagging named entities, which is described in [Chapter 7.5](https://www.nltk.org/book/ch07.html#sec-ner) of the NLTK book."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrCifMSL627g"
      },
      "source": [
        "sent = \"\"\"The 2020 Nobel Prize in Physics is awarded to Roger Penrose, Reinhard\n",
        "Genzel and Andrea Ghez for their work on black holes.\"\"\"\n",
        "\n",
        "sent_tokens = nltk.word_tokenize(sent)\n",
        "sent_tagged = nltk.pos_tag(sent_tokens)\n",
        "sent_ner = nltk.ne_chunk(sent_tagged)\n",
        "\n",
        "print(sent_ner)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsgZHcvZIa46"
      },
      "source": [
        "The NLTK book shows a list of commonly used named entity categories along with examples:\n",
        "\n",
        "NE Type | Examples\n",
        "--- | ---\n",
        "ORGANIZATION | Georgia-Pacific Corp., WHO\n",
        "PERSON | Eddy Bonte, President Obama\n",
        "LOCATION | Murray River, Mount Everest\n",
        "DATE | June, 2008-06-29\n",
        "TIME | two fifty a m, 1:30 p.m.\n",
        "MONEY | 175 million Canadian Dollars, GBP 10.40\n",
        "PERCENT | twenty pct, 18.75 %\n",
        "FACILITY | Washington Monument, Stonehenge\n",
        "GPE | South East Asia, Midlothian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUn6IJX0hOqA"
      },
      "source": [
        "# Assignment\n",
        "Answer the following questions and hand in your solution in Canvas before 23:59, October 18th. Remember to save your file before uploading it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeUG6lCihPrC"
      },
      "source": [
        "## Question 1\n",
        "Use `nltk.ne_chunk(tagged_sentence)` to identify the named entities in the sentences below. Note that you have to tokenize and tag the sentences first.\n",
        "\n",
        "(a) Print out and review the trees.\n",
        "\n",
        "(b) Find at least one error and leave a description of it as a comment or in a text cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kimEISKwjmY2"
      },
      "source": [
        "# On this day, October 16th (from https://en.wikipedia.org/wiki/October_16):\n",
        "sentences = [\n",
        "    \"1813 – The Sixth Coalition attacks Napoleon in the three-day Battle of Leipzig.\",\n",
        "    \"1923 – The Walt Disney Company is founded.\",\n",
        "    \"1968 – Yasunari Kawabata becomes the first Japanese person to be awarded the Nobel Prize in Literature.\",\n",
        "    \"1975 – Three-year-old Rahima Banu, from Bangladesh, is the last known case of naturally occurring smallpox.\",\n",
        "    \"2002 – The Bibliotheca Alexandrina opens in Egypt, commemorating the ancient library of Alexandria.\"\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your solution here\n"
      ],
      "metadata": {
        "id": "w_Q17RSI6OkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-fhUl__hQGf"
      },
      "source": [
        "## Question 2\n",
        "[SpaCy](https://spacy.io/) is another NLP library for Python. Try out its named entity recognition system on the sentences in Question 1.\n",
        "\n",
        "Answer the following questions in a text cell below:\n",
        "\n",
        "(a) Does it repeat any of the mistakes that NLTK makes?\n",
        "\n",
        "(b) Does it make any errors that NLTK doesn't?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usQVjoi675de"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "# Example\n",
        "text = \"\"\"The 2020 Nobel Prize in Physics is awarded to Roger Penrose, Reinhard\n",
        "Genzel and Andrea Ghez for their work on black holes.\"\"\"\n",
        "\n",
        "doc = nlp(text)\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4MOp81wydWL"
      },
      "source": [
        "# Your solution here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNnqJn93hQ4T"
      },
      "source": [
        "## Question 3\n",
        "Use regular expressions to try to find instances of the following relationships in the `reuters` corpus:\n",
        "1. Organizations or companies and their subsidiaries, divisions or parts, e.g.:\n",
        "  * *Moss Rosenberg Verft, a subsidiary of Kvaerner Industrier A/S*\n",
        "  * *Merrill Lynch Capital Partners, a unit of Merrill Lynch*\n",
        "2. Executives and the companies they work for, e.g.:\n",
        "  * *Isao Nakamura, president of Higashi Nippon*\n",
        "  *  *Henry Rosenberg, chairman of Crown Central Petroleum*\n",
        "\n",
        "Your results don't have to be perfect! Getting a few relevant matches is enough, but try to keep irrelevant results to a minimum."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJcbqv1mhQjH"
      },
      "source": [
        "import re\n",
        "from nltk.corpus import reuters\n",
        "nltk.download('reuters')\n",
        "\n",
        "# Create a copy of the text where there's only a single space between each word\n",
        "text = \" \".join(reuters.raw().split())\n",
        "\n",
        "# Example\n",
        "for m in re.findall(r'(?: [A-Z][a-z]+)+ said it acquired (?:[A-Z][a-z]+ )+', text):\n",
        "  print(m)\n",
        "\n",
        "# Note how normal groups and non-capturing groups work with re.findall():\n",
        "# a_string = \"a a b\"\n",
        "# re.findall(r'(a )+b', a_string): ['a '] (normal group)\n",
        "# re.findall(r'(?:a )+b', a_string): ['a a b'] (non-capturing group)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLg0V1ZTE_Hi"
      },
      "source": [
        "print(\"\\n1. Subsidiaries\")\n",
        "\n",
        "\n",
        "print(\"\\n2. Executives\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZlHx_4FhRoZ"
      },
      "source": [
        "## Question 4\n",
        "It's much easier to extract relationships from text that is tagged with named entities. This can be accomplished using the `nltk.sem.extract_rels()` function, as described in [Chapter 7.6](https://www.nltk.org/book/ch07.html#relation-extraction) of the NLTK book. The function takes two named entity categories and a regular expression as arguments and returns all instances where the pattern occurs between the two categories (allowing for up to 10 tokens between them, by default).\n",
        "\n",
        "The `ieer` (Information Extraction and Entity Recognition) corpus contains named entity annotations, such as `PER`, `ORG` and `LOC`. Find some instances of the following relationships using `nltk.sem.extract_rels()`:\n",
        "1. Professors and the organizations they work for, e.g.:\n",
        "  * *Roger Goldman, a law professor at St. Louis University*\n",
        "2. Family members e.g.,:\n",
        "  * *Louis XIV and his brother, Philippe*\n",
        "  * *Mildred Rosenbaum and her husband Stanley*\n",
        "3. People and where are from, e.g.:\n",
        "  * *Anna Rechnio of Poland*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHmcBIvhhRLs"
      },
      "source": [
        "from nltk.corpus import ieer\n",
        "nltk.download('ieer')\n",
        "\n",
        "# Example\n",
        "pattern = re.compile(r'.*\\bacquired?\\b')\n",
        "\n",
        "for doc in nltk.corpus.ieer.parsed_docs():\n",
        "  for rel in nltk.sem.extract_rels('ORG', 'ORG', doc, 'ieer', pattern):\n",
        "    print(nltk.sem.rtuple(rel))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_9-ByVN2bX_"
      },
      "source": [
        "# Your solution here\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}