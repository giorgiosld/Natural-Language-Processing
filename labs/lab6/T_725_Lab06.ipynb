{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giorgiosld/Natural-Language-Processing/blob/main/labs/lab6/T_725_Lab06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T-725 Natural Language Processing: Lab 6\n",
        "In today's lab, we will be working with the SHAP and Transformers libraries for explainability and debugging bias.\n",
        "\n",
        "To begin with, do the following:\n",
        "* Select `\"File\" > \"Save a copy in Drive\"` to create a local copy of this notebook that you can edit.\n",
        "* **Select `\"Runtime\" > \"Change runtime type\"`, and make sure that you have \"Hardware accelerator\" set to \"GPU\"**\n",
        "\n",
        "All examples are taken from the [SHAP](https://shap.readthedocs.io/en/stable/index.html) website.\n",
        "\n",
        "Install the required libraries and then **restart the runtime**:\n"
      ],
      "metadata": {
        "id": "oaOv_zTbtjbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "c2PVHdnIdb8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "3w3n9ub8djs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "KozT98-3rgWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "u5_mWjh03qoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SHAP\n",
        "SHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions (see [papers](https://github.com/slundberg/shap#citations) for details and citations).\n",
        "\n",
        "The Shapley value provides a principled way to explain the predictions of nonlinear models common in the field of machine learning. By interpreting a model trained on a set of features as a value function on a coalition of players, Shapley values provide a natural way to compute which features contribute to a prediction.\n",
        "\n",
        "The Shapley value is a solution concept in cooperative game theory and characterized by a collection of desirable properties.\n",
        "\n",
        "The setup is as follows: a coalition of players cooperates, and obtains a certain overall gain from that cooperation. Since some players may contribute more to the coalition than others or may possess different bargaining power (for example threatening to destroy the whole surplus), what final distribution of generated surplus among the players should arise in any particular game? Or phrased differently: how important is each player to the overall cooperation, and what payoff can he or she reasonably expect? The Shapley value provides one possible answer to this question."
      ],
      "metadata": {
        "id": "fACD8OWQunwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Emotion classification multiclass example\n",
        "\n",
        "This section demonstrates how to use the `Partition` explainer for a multiclass text classification scenario. Once the SHAP values are computed for a set of sentences we then visualize feature attributions towards individual classes. The text classifcation model we use is BERT fine-tuned on an emotion dataset to classify a sentence among six classes: *joy*, *sadness*, *anger*, *fear*, *love* and *surprise*."
      ],
      "metadata": {
        "id": "TJwbP2wxxBR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import transformers\n",
        "import datasets\n",
        "import shap"
      ],
      "metadata": {
        "id": "hkEJxthUxSyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the emotion dataset\n",
        "dataset  = datasets.load_dataset(\"emotion\", split = \"train\")\n",
        "data = pd.DataFrame({'text':dataset['text'],'emotion':dataset['label']})"
      ],
      "metadata": {
        "id": "HDT--tAYxVeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build a transformers pipline\n",
        "\n",
        "Note that we have set `return_all_scores=True` for the pipeline so we can observe the model's behavior for all classes, not just the top output."
      ],
      "metadata": {
        "id": "HuIK9kssyZjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"nateraw/bert-base-uncased-emotion\", use_fast=True)\n",
        "emotion_model = transformers.AutoModelForSequenceClassification.from_pretrained(\"nateraw/bert-base-uncased-emotion\").cuda()\n",
        "\n",
        "# build a pipeline object to do predictions\n",
        "pred = transformers.pipeline(\"text-classification\", model=emotion_model, tokenizer=tokenizer, device=0, return_all_scores=True)"
      ],
      "metadata": {
        "id": "9IgayMGzxVYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create an explainer for the pipeline\n",
        "\n",
        "A transformers `pipeline` object can be passed directly to `shap.Explainer`, which will then wrap the pipeline model as a `shap.models.TransformersPipeline` model and the pipeline tokenizer as a `shap.maskers.Text masker`."
      ],
      "metadata": {
        "id": "-YYl8h9vyneo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(pred)"
      ],
      "metadata": {
        "id": "BFddLZq-yuAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Compute SHAP values\n",
        "\n",
        "Explainers have the same method signature as the models they are explaining, so we just pass a list of strings for which to explain the classifications."
      ],
      "metadata": {
        "id": "moakPAgKyzLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(data['text'][:3])"
      ],
      "metadata": {
        "id": "FSD_FUb9yuz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualize the impact on all the output classes\n",
        "\n",
        "In the plots below, when you hover your mouse over an output class you get the explanation for that output class. When you click an output class name then that class remains the focus of the explanation visualization until you click another class.\n",
        "\n",
        "The base value is what the model outputs when the entire input text is masked, while $f_{outputclass}=(inputs)$\n",
        "is the output of the model for the full original input. The SHAP values explain in an addive way how the impact of unmasking each word changes the model output from the base value (where the entire input is masked) to the final prediction value."
      ],
      "metadata": {
        "id": "B7HplLUvy_fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values)"
      ],
      "metadata": {
        "id": "vec75vfey_8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualize the impact on a single class\n",
        "\n",
        "Since `Explanation` objects are sliceable we can slice out just a single output class to visualize the model output towards that class."
      ],
      "metadata": {
        "id": "mjEc4xyH04jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values[:, :, \"anger\"])"
      ],
      "metadata": {
        "id": "l6CccbU-yuwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plotting the top words impacting a specific class\n",
        "\n",
        "In addition to slicing, `Explanation` objects also support a set of reducing methods. Here we use the `.mean(0)` to take the average impact of all words towards the “joy” class. Note that here we are also averaging over three examples, to get a better summary you would want to use a larger portion of the dataset."
      ],
      "metadata": {
        "id": "k3FXs2kO0-Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.bar(shap_values[:,:,\"joy\"].mean(0))"
      ],
      "metadata": {
        "id": "NFsPogkf1NAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can sort the bar chart in decending order\n",
        "shap.plots.bar(shap_values[:,:,\"joy\"].mean(0), order=shap.Explanation.argsort)"
      ],
      "metadata": {
        "id": "CgdPVUqq1M2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Machine Translation Explanations\n",
        "This section demonstrates model explanations for a text to text scenario using a pretrained transformer model for machine translation. In this demo, we showcase explanations on a model for [English to French](https://huggingface.co/Helsinki-NLP/opus-mt-en-fr)."
      ],
      "metadata": {
        "id": "kZPsgbbk0-DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import shap\n",
        "import torch"
      ],
      "metadata": {
        "id": "aa1YhVwzgHaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "translation_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")"
      ],
      "metadata": {
        "id": "CGnj9FgnfAHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    \"Transformers have rapidly become the model of choice for NLP problems, replacing older recurrent neural network models\"\n",
        "]"
      ],
      "metadata": {
        "id": "3SVhAuW3jztN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(translation_model, tokenizer)\n",
        "shap_values = explainer(data)"
      ],
      "metadata": {
        "id": "rviJj_98ht9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values)"
      ],
      "metadata": {
        "id": "-2UPLDE4ht1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we can do the same thing with other languages. The [Helsinki NLP](https://huggingface.co/Helsinki-NLP) group, for example, has models in multiple other languages you can try out, such as for Icelandic to English (Helsinki-NLP/opus-mt-is-en) and vice versa (Helsinki-NLP/opus-mt-en-is)."
      ],
      "metadata": {
        "id": "-qOY-F61OYgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Open Ended GPT2 Text Generation Explanations\n",
        "This section shows how to get explanations for the output of GPT2 used for open ended text generation. In this demo, we use the pretrained GPT2 model provided by [Hugging Face](https://huggingface.co/gpt2) to explain the generated text by GPT2. We further showcase how to get explanations for custom output generated text and plot global input token importances for any output generated token."
      ],
      "metadata": {
        "id": "G_W3qZ4n3W27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import shap\n",
        "import torch"
      ],
      "metadata": {
        "id": "pFyJiVDv5TET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
        "nlg_model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "zYVxUwiD5Yyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we set certain model configurations. We need to define if the model is a decoder or encoder-decoder. This can be set through the ‘is_decoder’ or ‘is_encoder_decoder’ param in model’s config file. We can also set custom model generation parameters which will be used during the output text generation decoding process."
      ],
      "metadata": {
        "id": "ukIILGDT5ddS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set model decoder to true\n",
        "nlg_model.config.is_decoder=True\n",
        "# set text-generation params under task_specific_params\n",
        "nlg_model.config.task_specific_params[\"text-generation\"] = {\n",
        "    \"do_sample\": True,\n",
        "    \"max_length\": 50,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_k\": 50,\n",
        "    \"no_repeat_ngram_size\": 2\n",
        "}"
      ],
      "metadata": {
        "id": "WE2o6ffe5eLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define initial text:"
      ],
      "metadata": {
        "id": "cI-lTm_H5lyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = ['I enjoy walking with my cute dog']"
      ],
      "metadata": {
        "id": "n1v6eVV55h1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an explainer object and compute the SHAP values:"
      ],
      "metadata": {
        "id": "ZkG7qqIS5sjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(nlg_model, tokenizer)\n",
        "shap_values = explainer(s)"
      ],
      "metadata": {
        "id": "dJMQTvDS5wzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize shap explanations:"
      ],
      "metadata": {
        "id": "599tt7gi51GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values)"
      ],
      "metadata": {
        "id": "wTkAkLcp5ynn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Custom text generation and debugging biased outputs\n",
        "Below we demonstrate the process of how to explain the liklihood of generating a particular output sentence given an input sentence using the model. For example, we ask a question: Which country's inhabitant (target) in the sentence \"I know many people who are [target].\" would have a high liklilhood of generating the token \"vodka\" in the output sentence \"They love their vodka!\"? For this, we first define input-output sentence pairs"
      ],
      "metadata": {
        "id": "CHWbaFH_5SdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input\n",
        "x = [\n",
        "    \"I know many people who are Finnish.\",\n",
        "    \"I know many people who are Greek.\",\n",
        "    \"I know many people who are Australian.\",\n",
        "    \"I know many people who are American.\",\n",
        "    \"I know many people who are Italian.\",\n",
        "    \"I know many people who are Spanish.\",\n",
        "    \"I know many people who are German.\",\n",
        "    \"I know many people who are Indian.\"\n",
        "]"
      ],
      "metadata": {
        "id": "HSslfFN06khi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define output\n",
        "y = [\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\",\n",
        "    \"They love their vodka!\"\n",
        "]"
      ],
      "metadata": {
        "id": "ICDFRPBl6pTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap the model with a Teacher Forcing scoring class and create a Text masker:"
      ],
      "metadata": {
        "id": "4mZGgryk6wUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_model = shap.models.TeacherForcing(nlg_model, tokenizer)\n",
        "masker = shap.maskers.Text(tokenizer, mask_token = \"...\", collapse_mask_token=True)"
      ],
      "metadata": {
        "id": "s7rhBS8B6y4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an explainer:"
      ],
      "metadata": {
        "id": "9y1eESxk7Sr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.Explainer(teacher_forcing_model, masker)"
      ],
      "metadata": {
        "id": "_mWOZZun7Uii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate SHAP explanation values:"
      ],
      "metadata": {
        "id": "F7lm-o4O7Wzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = explainer(x, y)"
      ],
      "metadata": {
        "id": "eMIDTCnj7ZKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have generated the SHAP values, we can have a look at the contribution of tokens in the input driving the token \"vodka\" in the output sentence using the text plot. Just hover your mouse over \"vodka\" to see this for each example. You can also click on the word \"vodka\" to see this more clearsly.\n",
        "\n",
        "Note: The red color indicates a positive contribution while the blue color indicates negative contribution and the intensity of the color shows its strength in the respective direction."
      ],
      "metadata": {
        "id": "t3vuPjiA7dDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.text(shap_values)"
      ],
      "metadata": {
        "id": "0dx-BnDb7jfg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! Now you can gain better insight into your models using SHAP 😀"
      ],
      "metadata": {
        "id": "heV0SNz_6lR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Assignment\n",
        "\n",
        "Complete the following questions and hand in your solution in Canvas before 23:59 Friday, October 4th. Remember to save your file before uploading it."
      ],
      "metadata": {
        "id": "oj0hiGUD7-cQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1\n",
        "\n",
        "Visualize the relation of the input to the emotions.\n",
        "\n",
        "Which words impact each class the most?"
      ],
      "metadata": {
        "id": "uv9-q5ZYW6PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "green_mile = [\"\",\"\"\"\n",
        "I want it over and done. I do. I'm tired, boss. Tired of bein' on the road, lonely\n",
        "as a sparrow in the rain. Tired of not ever having me a buddy to be with, or tell\n",
        "me where we's coming from or going to, or why. Mostly I'm tired of people being\n",
        "ugly to each other. I'm tired of all the pain I feel and hear in the world everyday.\n",
        "There's too much of it. It's like pieces of glass in my head all the time. Can you\n",
        "understand?\n",
        "\"\"\",\"\"]"
      ],
      "metadata": {
        "id": "4bcPxADKYBDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your solution here"
      ],
      "metadata": {
        "id": "B86vFs1aW597"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 2\n",
        "\n",
        "Visualize the explanations for machine translation models for two languages you speak or have the best knowledge of. Try running this for three different sentences.\n",
        "\n",
        "Does the output sequence correlate with the input sequence in a way you would have expected?"
      ],
      "metadata": {
        "id": "ixGF3oS08CWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your solution here"
      ],
      "metadata": {
        "id": "vP5rEz9h9ONn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 3\n",
        "\n",
        "Use the method to debug biased output on a different kind of bias. For example, gender bias related to professions like doctors.\n",
        "\n",
        "Try one more example of your choosing."
      ],
      "metadata": {
        "id": "AigAZRH4VjuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution to gender bias"
      ],
      "metadata": {
        "id": "YwnwmXDaWKFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution to your own example"
      ],
      "metadata": {
        "id": "DTgeKCl1WNcq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}